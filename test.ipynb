{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net4 import ImpactNetV4, M, create_default_net\n",
    "import numpy as np\n",
    "import utils as u\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.viewer import ImageViewer\n",
    "from skimage import io\n",
    "from utils import get_images\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray, rgb2grey\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "%matplotlib inline\n",
    "data = [\n",
    "    {\n",
    "        'value_2d': image['value'].reshape(M, M),\n",
    "        'value': image['value'],\n",
    "        'label': image['label']\n",
    "    } for image in u.get_image_data('medium')\n",
    "]\n",
    "\n",
    "def save(path, image): io.imsave(path, image)\n",
    "\n",
    "def scatter(data):\n",
    "    plt.scatter([i for i in range(len(data))], data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "net = ImpactNetV2(M, learning_rate, length, hidden_layer_size, u.get_image_data())\n",
    "net.train()\n",
    "pickle.dump(net, open('trained_net2.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train various nets, output their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = []\n",
    "for i in range(100):\n",
    "    new_net = create_default_net()\n",
    "    new_net.train(False)\n",
    "    counter_correct = 0\n",
    "    result_total = 0\n",
    "    plot_data = []\n",
    "    for image in data:\n",
    "        result = new_net.evaluate(image['value'])\n",
    "        result_total += result\n",
    "        plot_data.append(result)\n",
    "\n",
    "        verdict = \"negative\"\n",
    "        if result > 0.5: verdict == \"positive\"\n",
    "\n",
    "        assesment = 'WRONG'\n",
    "        if verdict == image['label']:\n",
    "            counter_correct += 1\n",
    "            assesment = 'CORRECT'\n",
    "\n",
    "        # print(f'{result}: {verdict}\\nlabel: {image[\"label\"]}\\nassesment: {assesment}')\n",
    "        # plt.imshow(image['value_2d'])\n",
    "        # plt.show()\n",
    "    # print(f'accuracy: {counter_correct / len(data)}\\nmean result: {result_total / len(data)}\\nstd:{np.std(plot_data)}')\n",
    "    # plt.scatter([i for i in range(len(plot_data))], plot_data)\n",
    "    # plt.show()\n",
    "    nets.append({\n",
    "        'net': new_net,\n",
    "        'std': np.std(plot_data),\n",
    "        'accuracy': counter_correct / len(data),\n",
    "        'mean_result': result_total / len(data),\n",
    "        'plot_data': plot_data\n",
    "    })\n",
    "for net in nets: \n",
    "    print(f\"NET NUMBER {nets.index(net)}\\naccuracy: {net['accuracy']}\\nmean result: {net['mean_result']}\\nstd: {net['std']}\")\n",
    "    plt.scatter([i for i in range(len(net['plot_data']))], net['plot_data'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the same net multiple times, output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "nets = []\n",
    "new_net = create_default_net()\n",
    "for i in range(100):\n",
    "    new_net.train(False)\n",
    "    counter_correct = 0\n",
    "    result_total = 0\n",
    "    plot_data = []\n",
    "    for image in data:\n",
    "        result = new_net.evaluate(image['value'])\n",
    "        result_total += result\n",
    "        plot_data.append(result)\n",
    "\n",
    "        verdict = \"negative\"\n",
    "        if result > 0.5: verdict == \"positive\"\n",
    "\n",
    "        assesment = 'WRONG'\n",
    "        if verdict == image['label']:\n",
    "            counter_correct += 1\n",
    "            assesment = 'CORRECT'\n",
    "\n",
    "        # print(f'{result}: {verdict}\\nlabel: {image[\"label\"]}\\nassesment: {assesment}')\n",
    "        # plt.imshow(image['value_2d'])\n",
    "        # plt.show()\n",
    "    # print(f'accuracy: {counter_correct / len(data)}\\nmean result: {result_total / len(data)}\\nstd:{np.std(plot_data)}')\n",
    "    # plt.scatter([i for i in range(len(plot_data))], plot_data)\n",
    "    # plt.show()\n",
    "    nets.append({\n",
    "        'net': new_net,\n",
    "        'std': np.std(plot_data),\n",
    "        'accuracy': counter_correct / len(data),\n",
    "        'mean_result': result_total / len(data),\n",
    "        'plot_data': plot_data\n",
    "    })\n",
    "for net in nets: \n",
    "    print(f\"NET NUMBER {nets.index(net)}\\naccuracy: {net['accuracy']}\\nmean result: {net['mean_result']}\\nstd: {net['std']}\")\n",
    "    plt.scatter([i for i in range(len(net['plot_data']))], net['plot_data'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, len(net.weights)):\n",
    "#     for j in range(len(net.weights[i])):\n",
    "#         #print(net.weights[i][j])\n",
    "#         plt.scatter(i, np.mean(net.weights[i][j]))\n",
    "# Make an array with ones in the shape of an 'X'\n",
    "import matplotlib.cm as cm\n",
    "def set_size(w,h, ax=None):\n",
    "    \"\"\" w, h: width, height in inches \"\"\"\n",
    "    if not ax: ax=plt.gca()\n",
    "    l = ax.figure.subplotpars.left\n",
    "    r = ax.figure.subplotpars.right\n",
    "    t = ax.figure.subplotpars.top\n",
    "    b = ax.figure.subplotpars.bottom\n",
    "    figw = float(w)/(r-l)\n",
    "    figh = float(h)/(t-b)\n",
    "    ax.figure.set_size_inches(figw, figh)\n",
    "\n",
    "for i in net.weights[1:len(net.weights)]:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(i, interpolation='nearest', cmap=cm.Greys_r)\n",
    "    set_size(10,150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import adjust_gamma\n",
    "for image in data:\n",
    "    adjusted = adjust_gamma(image['value_2d'], 3)\n",
    "    plt.imshow(image['value_2d'], cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(adjusted, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(100): stdest_net.train(False)\n",
    "counter_correct = 0\n",
    "result_total = 0\n",
    "plot_data = []\n",
    "for image in data:\n",
    "    result = new_net.evaluate(image['value'])\n",
    "    result_total += result\n",
    "    plot_data.append(result)\n",
    "\n",
    "    verdict = \"negative\"\n",
    "    if result > 0.5: verdict == \"positive\"\n",
    "\n",
    "    assesment = 'WRONG'\n",
    "    if verdict == image['label']:\n",
    "        counter_correct += 1\n",
    "        assesment = 'CORRECT'\n",
    "\n",
    "    # print(f'{result}: {verdict}\\nlabel: {image[\"label\"]}\\nassesment: {assesment}')\n",
    "    # plt.imshow(image['value_2d'])\n",
    "    # plt.show()\n",
    "print(f'accuracy: {counter_correct / len(data)}\\nmean result: {result_total / len(data)}\\nstd:{np.std(plot_data)}')\n",
    "plt.scatter([i for i in range(len(plot_data))], plot_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHY? I DON'T UNDERSTAND.\n",
    "\n",
    "### Cool nets\n",
    "1. 68 - the 1est one\n",
    "2. 65 - the stdest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "net = create_default_net(cost_function_type='cross-entropy')\n",
    "cost_over_training_examples = []\n",
    "def per_example_logging_callback(net, result):\n",
    "    cost_over_training_examples.append(net.cost(net.evaluate(result['values']['activations'][0]), result['label'])['value'])\n",
    "net.train(logging=False, per_example_logging_callback=per_example_logging_callback)\n",
    "scatter(cost_over_training_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "--------------------------\n",
    "# MISC AREA\n",
    "## VERY CHAOTIC PROCEED WITH CAUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHITENESS EMPHASIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from net4 import ImpactNetV4, M, create_default_net\n",
    "import numpy as np\n",
    "import utils as u\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.viewer import ImageViewer\n",
    "from skimage import io\n",
    "from utils import get_images\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray, rgb2grey\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.fftpack import fft\n",
    "%matplotlib inline\n",
    "\n",
    "def max_acc(m):\n",
    "    return acc(knife_matrix(m))\n",
    "\n",
    "def knife_matrix(m):\n",
    "    import numpy as np\n",
    "    out = []\n",
    "    for i in range(m):\n",
    "        row = np.array([])\n",
    "        if i % 2 == 0: row = [0 for j in range(m)]\n",
    "        else: row = [1 for j in range(m)]\n",
    "        out.append(row)\n",
    "    return np.array(out)\n",
    "\n",
    "def acc(im):\n",
    "    acutance = 0\n",
    "    # print(im.shape)\n",
    "    w = im.shape[0]\n",
    "    l = im.shape[1]\n",
    "    for row in range(len(im)):\n",
    "        for col in range(len(im[row])): # For each pixel\n",
    "            local_acutance = 0\n",
    "            ref = im[row][col] # Magnitude of value current pixel, reference value\n",
    "\n",
    "            for i in [row-1, row, row+1]:\n",
    "                for j in [col-1, col, col+1]:\n",
    "                    if not ( (i < 0) or (i > w - 1) or (j < 0) or (j > l - 1) or (i == row and j == col) ):\n",
    "                        # These for loops and if statement go through all the row, col coordinates of the neighboring pixels\n",
    "                        local_acutance += abs(ref - im[i][j])\n",
    "            acutance += local_acutance\n",
    "    return acutance\n",
    "\n",
    "def gradient_array(arr):\n",
    "    out = arr[:]\n",
    "    for i in range(1, len(arr)):\n",
    "        out[i] = arr[i] - arr[i-1]\n",
    "    out[0] = out[1]\n",
    "    return out\n",
    "\n",
    "def show(im): plt.imshow(im, cmap='gray'); plt.show()\n",
    "def plot(dat): plt.plot(dat); plt.show()\n",
    "\n",
    "data = []\n",
    "accut = lambda m: 6*(m**2)-(10*m)+4\n",
    "\n",
    "def rgb2gray_emph_whiteness(image, n=6, k=4):\n",
    "    m = ( (10**k) / ((255*3)**n) )\n",
    "    f = lambda x: m * (x**n)\n",
    "    to_gray = []\n",
    "    for row in image:\n",
    "        out_row = [\n",
    "            f(np.sum(col)) / 10000 for col in row\n",
    "        ]\n",
    "        to_gray.append(out_row)\n",
    "    to_gray = np.array(to_gray)\n",
    "    return to_gray\n",
    "\n",
    "def emphasize_3rd_quarter(dist):\n",
    "    # Most of the impact-like gradient changes tend to happen in around the half to 3/4 region of the magnitude distribution\n",
    "    d = dist[:]\n",
    "    for i in range(len(dist)):\n",
    "        if not (((i / len(dist)) >= 0.5) and ((i / len(dist)) <= 0.75)):\n",
    "            d[i] = 0\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACUTANCE EMPHASIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-4d2e4fdacca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mmaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmaps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macutance_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb2gray_emph_whiteness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7ea13f4499a6>\u001b[0m in \u001b[0;36mrgb2gray_emph_whiteness\u001b[1;34m(image, n, k)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mto_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         out_row = [\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         ]\n",
      "\u001b[1;32m<ipython-input-15-7ea13f4499a6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         out_row = [\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         ]\n\u001b[0;32m     68\u001b[0m         \u001b[0mto_gray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2228\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2229\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[0;32m     75\u001b[0m                   if v is not np._NoValue}\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def acutance_map(image):\n",
    "    image = image[:]\n",
    "    countc = 0\n",
    "    countr = 0\n",
    "    w = image.shape[0] # Width\n",
    "    l = image.shape[1] # Length\n",
    "    #print(count)\n",
    "    s=100\n",
    "    r = int(0.05 * (w + l) / 2) # Radius is proportional to average of height and width.\n",
    "    acutance_map = np.zeros_like(image)\n",
    "\n",
    "    regions = []\n",
    "    gradients = []\n",
    "    counter = 0\n",
    "\n",
    "    for row in range(0, len(image), r):\n",
    "        for col in range(0, len(image[row]), r):\n",
    "            region = image[\n",
    "                max(0, row - r) : min(w - 1, row + r), # Ensures that indices are within range.\n",
    "                max(0, col - r) : min(l - 1, col + r)\n",
    "            ]\n",
    "\n",
    "            gradient = np.gradient(np.sort(rgb2gray(region).flatten())) # all of the pixels sorted from lowest to highest brightness\n",
    "            avg_gradient = np.mean(abs(gradient)) # take mean gradient of the \n",
    "            #plot(gradient)\n",
    "            #plot(fft(gradient))\n",
    "            #show(region)\n",
    "            regions.append(region)\n",
    "            gradients.append(gradient)\n",
    "            \n",
    "            acutance_map[\n",
    "                max(0, row - r) : min(w - 1, row + r),\n",
    "                max(0, col - r) : min(l - 1, col + r)\n",
    "            ] += avg_gradient*100\n",
    "    return normalize(acutance_map)\n",
    "\n",
    "image = rgb2gray_emph_whiteness(io.imread('images/net_images_whole/357.png'))\n",
    "#print(image)\n",
    "images = get_images()\n",
    "\n",
    "maps = []\n",
    "for image in images: maps.append(acutance_map(rgb2gray_emph_whiteness(image)))\n",
    "\n",
    "fig, axs = plt.subplots(len(images), 2, figsize=(8, len(images)))\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    axs[i][0].imshow(images[i], cmap='gray')\n",
    "    axs[i][1].plot(maps[i])\n",
    "fig.set_tight_layout(True)\n",
    "plt.savefig('gradient_maps.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bit6d65511200164d93a771008c359d5164",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}